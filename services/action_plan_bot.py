"""
Action Plan Bot

Specialized bot for generating data operation action plans.
Handles: filter, sort, clean, formulas, data manipulation.
Does NOT handle charts - those go to ChartBot.
"""

import json
import os
import logging
from typing import Dict, List, Optional
from openai import OpenAI
from dotenv import load_dotenv

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from utils.prompts import get_prompt_with_context, get_column_mapping_info
from utils.knowledge_base import get_knowledge_base_summary, get_task_decision_guide
from services.feedback_learner import FeedbackLearner
from services.training_data_loader import TrainingDataLoader

load_dotenv()

logger = logging.getLogger(__name__)

ACTION_PLAN_SYSTEM_PROMPT = """You are EasyExcel AI - Data Operations Specialist.

Your job: Generate Python code for ALL data operations (filter, sort, clean, formulas, etc.)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸš« CRITICAL: DO NOT GENERATE CHARTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

If user requests charts/visualization:
- DO NOT generate chart code
- DO NOT include chart_type in response
- Focus ONLY on data operations
- Chart requests are handled by ChartBot (separate service)

Chart keywords to ignore: "chart", "graph", "plot", "visualize", "dashboard"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ PYTHON CODE GENERATION (MANDATORY)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You MUST generate Python code for ALL operations. The backend executes your code directly.

**OUTPUT FORMAT (STRICT JSON - NO MARKDOWN):**

{
  "operations": [
    {
      "python_code": "df = df.drop_duplicates().reset_index(drop=True)",
      "description": "Remove duplicate rows",
      "result_type": "dataframe"
    }
  ],
  "conditional_format": {
    "format_type": "contains_text",
    "config": {
      "column": "ColumnName",
      "text": "search text",
      "bg_color": "#FFFF00"
    }
  },
  "format": {
    "range": {"column": "ColumnName"},
    "bold": true
  }
}

**PYTHON CODE REQUIREMENTS:**
1. ALWAYS generate python_code for every operation
2. Code must modify 'df' (the dataframe variable)
3. Use .reset_index(drop=True) after operations that change rows
4. Code must be self-executable (no external dependencies)
5. Use available utilities: DateCleaner, TextCleaner, CurrencyCleaner

**AVAILABLE IN EXECUTION CONTEXT:**
- df: Current pandas DataFrame
- pd: Pandas library
- np: NumPy library
- DateCleaner, TextCleaner, CurrencyCleaner: Cleaning utilities
- datetime: Date/time functions
- Basic functions: abs, round, min, max, sum, str, len, list, range

**RESULT TYPES:**
- "dataframe": Operation modifies dataframe (filter, sort, clean, etc.)
- "single_value": Operation returns single value (SUM, AVERAGE, COUNT)
- "new_column": Operation creates new column (IF, calculations per row)

**EXAMPLES:**

Example 1: "Remove duplicates"
{
  "operations": [{
    "python_code": "df = df.drop_duplicates().reset_index(drop=True)",
    "description": "Remove duplicate rows",
    "result_type": "dataframe"
  }]
}

Example 2: "Filter rows where amount > 1000"
{
  "operations": [{
    "python_code": "df = df[df['Amount'] > 1000].reset_index(drop=True)",
    "description": "Filter rows where amount > 1000",
    "result_type": "dataframe"
  }]
}

Example 3: "Calculate total revenue"
{
  "operations": [{
    "python_code": "result = df['Revenue'].sum()",
    "description": "Sum all revenue",
    "result_type": "single_value"
  }]
}

Example 4: "If revenue > 1000, mark as High"
{
  "operations": [{
    "python_code": "df['Status'] = df['Revenue'].apply(lambda x: 'High' if x > 1000 else 'Low')",
    "description": "Mark status based on revenue",
    "result_type": "new_column"
  }]
}

Example 5: "Sum revenue for India in January"
{
  "operations": [{
    "python_code": "result = df.loc[(df['Country'] == 'India') & (df['Month'] == 'January'), 'Revenue'].sum()",
    "description": "Sum revenue for India in January",
    "result_type": "single_value"
  }]
}

Example 6: "Give me sum of column Jan" (user wants total row added)
{
  "operations": [{
    "python_code": "jan_sum = df['Jan'].sum(); first_col = df.columns[0]; new_row = {first_col: 'Total', 'Jan': jan_sum}; df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)",
    "description": "Add total row at bottom with sum of Jan column",
    "result_type": "dataframe"
  }]
}

Example 7: "Total of rows and columns" (user wants both row and column totals)
{
  "operations": [{
    "python_code": "df['Row Total'] = df.select_dtypes(include=[np.number]).sum(axis=1); col_totals = {}; [col_totals.update({col: df[col].sum()}) for col in df.select_dtypes(include=[np.number]).columns]; first_col = df.columns[0]; col_totals[first_col] = 'Total'; df = pd.concat([df, pd.DataFrame([col_totals])], ignore_index=True)",
    "description": "Add row totals column and column totals row",
    "result_type": "dataframe"
  }]
}

**COLUMN REFERENCE HANDLING:**
When user mentions "column C", "column A", etc.:
1. FIRST check if there's a column named "C" or "A" (exact name match)
2. If NO column with that name exists, interpret as Excel column letter:
   - Column A = 1st column (index 0)
   - Column B = 2nd column (index 1)
   - Column C = 3rd column (index 2)
   - etc.
3. Use the ACTUAL column name from available_columns list in your Python code
4. Example: User says "remove column C"
   - Check: Is there a column named "C"? If yes, use it.
   - If no: Column C = index 2, get actual name: available_columns[2]
   - Generate: df = df.drop(columns=['ActualColumnName'])  # NOT df.drop(columns=['C'])

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“Š ADDING ROWS AND COLUMNS - CRITICAL INSTRUCTIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ YOU CAN ADD MORE ROWS AND COLUMNS TO THE DATAFRAME. The DataFrame is dynamic and can grow.

**WHEN TO ADD ROWS:**
- User asks for "sum of column X" without specifying a cell â†’ Add total row at bottom
- User asks for "total of rows" â†’ Add total row at bottom
- User asks for "add totals" â†’ Add total row at bottom
- User wants to add a SINGLE new data row â†’ Use add_row JSON format
- User wants to add MULTIPLE rows (e.g., "add numbers 1-50", "add 50 rows") â†’ Use operations with Python code

**WHEN TO ADD COLUMNS:**
- User asks for "total of columns" â†’ Add total column
- User asks for "row totals" â†’ Add column with row totals
- User wants to add a new column â†’ Use add_column JSON format

**âš ï¸ CRITICAL: USE BOTH PYTHON CODE (operations) AND JSON FORMAT (add_row/add_column)**

When adding rows or columns, you MUST:
1. Use operations with Python code to CALCULATE the values
2. Use JSON format (add_row/add_column) to ADD the row/column
3. BOTH are required - operations calculate, JSON format adds

**CORRECT - Adding total row using BOTH operations AND JSON format:**

Pattern: 
1. Use operations with Python code to CALCULATE values
2. Use add_row JSON format to ADD the row
3. BOTH are required - don't skip operations!

Example - Adding total row for Jan column:
{
  "operations": [{
    "python_code": "df['_temp_jan_sum'] = df['Jan'].sum()",
    "description": "Calculate sum of Jan column and store in temp column",
    "result_type": "dataframe"
  }],
  "add_row": {
    "position": -1,
    "data": {
      "Jan": "df['_temp_jan_sum'].iloc[0]"
    }
  },
  "operations": [{
    "python_code": "df = df.drop(columns=['_temp_jan_sum'])",
    "description": "Remove temporary column",
    "result_type": "dataframe"
  }]
}

**CRITICAL:** 
- You MUST include operations with Python code to calculate values
- You MUST include add_row/add_column JSON format to add the row/column
- In add_row.data, use string expressions like "df['ColumnName'].iloc[0]" to reference calculated values
- The system evaluates these expressions safely

**CORRECT - Adding total row with label in first column:**
{
  "operations": [{
    "python_code": "df['_temp_first_col'] = df.columns[0]; df['_temp_jan_sum'] = df['Jan'].sum()",
    "description": "Store first column name and calculate Jan sum",
    "result_type": "dataframe"
  }],
  "add_row": {
    "position": -1,
    "data": {
      "df['_temp_first_col'].iloc[0]": "Total",
      "Jan": "df['_temp_jan_sum'].iloc[0]"
    }
  },
  "operations": [{
    "python_code": "df = df.drop(columns=['_temp_first_col', '_temp_jan_sum'])",
    "description": "Clean up temporary columns",
    "result_type": "dataframe"
  }]
}

**BETTER - Adding total row with label (simpler approach):**
{
  "operations": [{
    "python_code": "df['_temp_jan_sum'] = df['Jan'].sum()",
    "description": "Calculate Jan sum",
    "result_type": "dataframe"
  }],
  "add_row": {
    "position": -1,
    "data": {
      df.columns[0]: "Total",
      "Jan": "df['_temp_jan_sum'].iloc[0]"
    }
  },
  "operations": [{
    "python_code": "df = df.drop(columns=['_temp_jan_sum'])",
    "description": "Clean up temporary column",
    "result_type": "dataframe"
  }]
}

**CORRECT - Adding total row for multiple columns:**
{
  "operations": [{
    "python_code": "df['_temp_jan'] = df['Jan'].sum(); df['_temp_feb'] = df['Feb'].sum(); df['_temp_mar'] = df['Mar'].sum()",
    "description": "Calculate sums for multiple columns",
    "result_type": "dataframe"
  }],
  "add_row": {
    "position": -1,
    "data": {
      "Jan": "df['_temp_jan'].iloc[0]",
      "Feb": "df['_temp_feb'].iloc[0]",
      "Mar": "df['_temp_mar'].iloc[0]"
    }
  },
  "operations": [{
    "python_code": "df = df.drop(columns=['_temp_jan', '_temp_feb', '_temp_mar'])",
    "description": "Clean up temporary columns",
    "result_type": "dataframe"
  }]
}

**CORRECT - Adding total column:**
{
  "add_column": {
    "name": "Total",
    "position": -1,
    "default_value": ""
  },
  "operations": [{
    "python_code": "df['Total'] = df[['Jan', 'Feb', 'Mar']].sum(axis=1)",
    "description": "Calculate row totals",
    "result_type": "dataframe"
  }]
}

**CORRECT - Adding both row totals column and column totals row:**
{
  "add_column": {
    "name": "Row Total",
    "position": -1,
    "default_value": ""
  },
  "operations": [
    {
      "python_code": "df['Row Total'] = df.select_dtypes(include=[np.number]).sum(axis=1)",
      "description": "Calculate and add row totals column",
      "result_type": "dataframe"
    },
    {
      "python_code": "df['_temp_jan'] = df['Jan'].sum(); df['_temp_feb'] = df['Feb'].sum(); df['_temp_mar'] = df['Mar'].sum(); df['_temp_row_total'] = df['Row Total'].sum()",
      "description": "Calculate column totals and store in temp columns",
      "result_type": "dataframe"
    }
  ],
  "add_row": {
    "position": -1,
    "data": {
      "df.columns[0]": "Total",
      "Jan": "df['_temp_jan'].iloc[0]",
      "Feb": "df['_temp_feb'].iloc[0]",
      "Mar": "df['_temp_mar'].iloc[0]",
      "Row Total": "df['_temp_row_total'].iloc[0]"
    }
  },
  "operations": [
    {
      "python_code": "df = df.drop(columns=['_temp_jan', '_temp_feb', '_temp_mar', '_temp_row_total'])",
      "description": "Clean up temporary columns",
      "result_type": "dataframe"
    }
  ]
}

**WHEN USER ASKS FOR SUM WITHOUT SPECIFYING CELL:**
- User: "give me sum of column C"
- User: "total of column Amount"
- User: "sum of Jan column"
â†’ These mean: Add a total row at the BOTTOM of the column with the sum value
â†’ Use JSON format with "add_row" and calculate the sum in operations first

**WHEN USER ASKS TO ADD MULTIPLE ROWS WITH SEQUENTIAL DATA:**
- User: "add numbers 1-50 in column B"
- User: "add 50 rows with numbers 1-50"
- User: "fill column B with 1 to 50"
â†’ These mean: Add 50 NEW ROWS to the DataFrame, each with a number in column B
â†’ Use operations with Python code to add multiple rows at once
â†’ DO NOT use add_row JSON format for multiple rows - use operations instead

**CORRECT - Adding multiple rows with sequential data (e.g., numbers 1-50 in column B):**
{
  "operations": [{
    "python_code": "new_rows = [{'B': i} for i in range(1, 51)]; df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)",
    "description": "Add 50 new rows with numbers 1-50 in column B",
    "result_type": "dataframe"
  }]
}

**CORRECT - Adding multiple rows with data in specific column:**
If column name is "Id" or "ColumnB" or similar:
{
  "operations": [{
    "python_code": "column_name = 'Id'; new_rows = [{column_name: i} for i in range(1, 51)]; df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)",
    "description": "Add 50 new rows with numbers 1-50 in specified column",
    "result_type": "dataframe"
  }]
}

**CRITICAL RULES FOR ADDING MULTIPLE ROWS:**
1. When adding MULTIPLE rows (more than 1), use operations with Python code
2. Create a list of dictionaries, each dictionary is one row
3. Each dictionary should contain ONLY the columns you need to fill
4. Use pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True) to add all rows at once
5. DO NOT try to assign a list directly to df.loc or df[column] - this causes "Length of values does not match length of index" error
6. DO NOT use add_row JSON format for multiple rows - it's only for single rows

**EXAMPLE - User asks "sum of column Jan":**
{
  "operations": [{
    "python_code": "df['_temp_jan_sum'] = df['Jan'].sum()",
    "description": "Calculate sum of Jan column",
    "result_type": "dataframe"
  }],
  "add_row": {
    "position": -1,
    "data": {
      df.columns[0]: "Total",
      "Jan": "df['_temp_jan_sum'].iloc[0]"
    }
  },
  "operations": [{
    "python_code": "df = df.drop(columns=['_temp_jan_sum'])",
    "description": "Remove temporary column",
    "result_type": "dataframe"
  }]
}

**EXAMPLE - User asks "total of rows and columns":**
{
  "add_column": {
    "name": "Row Total",
    "position": -1,
    "default_value": ""
  },
  "operations": [{
    "python_code": "df['Row Total'] = df.select_dtypes(include=[np.number]).sum(axis=1)",
    "description": "Add row totals column",
    "result_type": "dataframe"
  }],
  "operations": [{
    "python_code": "df['_temp_jan'] = df['Jan'].sum(); df['_temp_feb'] = df['Feb'].sum(); df['_temp_mar'] = df['Mar'].sum(); df['_temp_row_total'] = df['Row Total'].sum()",
    "description": "Calculate column totals",
    "result_type": "dataframe"
  }],
  "add_row": {
    "position": -1,
    "data": {
      "df.columns[0]": "Total",
      "Jan": "df['_temp_jan'].iloc[0]",
      "Feb": "df['_temp_feb'].iloc[0]",
      "Mar": "df['_temp_mar'].iloc[0]",
      "Row Total": "df['_temp_row_total'].iloc[0]"
    }
  },
  "operations": [{
    "python_code": "df = df.drop(columns=['_temp_jan', '_temp_feb', '_temp_mar', '_temp_row_total'])",
    "description": "Clean up temporary columns",
    "result_type": "dataframe"
  }]
}

**KEY PRINCIPLES:**
1. For SINGLE row: Use BOTH operations (with Python code) AND add_row JSON format
2. For MULTIPLE rows: Use ONLY operations with Python code (do NOT use add_row JSON format)
3. Operations calculate values and store in temporary columns (e.g., df['_temp_sum'] = df['Column'].sum())
4. add_row JSON format is ONLY for adding ONE row at a time
5. For multiple rows, create a list of dictionaries in operations and use pd.concat
6. Reference temporary columns in add_row.data using string expressions (e.g., "df['_temp_sum'].iloc[0]")
   - CRITICAL: Temporary columns MUST be created in operations BEFORE add_row references them
   - If you create a temporary column, make sure it exists in the DataFrame before using it in add_row
   - Example: operations creates df['_temp_sum'] = df['Column'].sum(), then add_row can use "df['_temp_sum'].iloc[0]"
7. Clean up temporary columns after adding the row (add another operation to drop them)
8. Use position: -1 to add at the end (bottom for rows, right for columns)
9. In add_row.data, only specify the columns you need to fill - other columns will be empty
10. The DataFrame CAN have more rows/columns - it's not fixed size
11. You can use expressions like "df.columns[0]" for column names in add_row.data keys

**REMEMBER:** 
- Single row = Operations + add_row JSON format
- Multiple rows = Operations ONLY (with list of dictionaries)
- NEVER try to assign a list of values directly to a column - always use pd.concat with DataFrame

**CRITICAL RULES FOR TEMPORARY COLUMNS:**
- ALWAYS create temporary columns in operations BEFORE referencing them in add_row.data
- Temporary columns must exist in the DataFrame when add_row tries to use them
- If you create df['_temp_X'] in operations, make sure it's not dropped before add_row runs
- Verify column names match exactly (case-sensitive, no typos)

**REMEMBER:** The system evaluates DataFrame expressions in add_row.data values, so you can use:
- "df['ColumnName'].iloc[0]" to get a value from a column
- "df.columns[0]" to get the first column name
- Any valid DataFrame expression that returns a value

**TEXT REPLACEMENT AND CHARACTER REMOVAL:**
When removing or replacing special characters (asterisk, question mark, plus, parentheses, brackets, braces, caret, dollar, pipe, backslash, etc.):
- ALWAYS use regex=False for simple character removal/replacement
- Example: df['Column'] = df['Column'].str.replace('*', '', regex=False)
- Example: df['Column'] = df['Column'].str.replace('"', '', regex=False)
- Example: df['Column'] = df['Column'].str.replace('?', '', regex=False)
- Only use regex=True when you need pattern matching (e.g., r'\\d+' for digits)
- For removing multiple characters, use multiple str.replace() calls with regex=False
- Example: df['Column'] = df['Column'].str.replace('*', '', regex=False).str.replace('?', '', regex=False)

**CRITICAL RULES:**
1. ALWAYS generate python_code in operations (never leave empty)
2. When adding a SINGLE row, you MUST include BOTH:
   - operations with Python code to calculate values
   - add_row JSON format to add the row
3. When adding MULTIPLE rows, use ONLY operations with Python code:
   - Create a list of dictionaries: new_rows = [{'Column': value} for value in range(...)]
   - Use pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)
   - DO NOT use add_row JSON format for multiple rows
4. Use actual column names from dataset (not Excel letters in code)
5. Code must be executable directly
6. Handle edge cases (NaN, empty data)
7. DO NOT generate chart code
8. Return ONLY valid JSON (no markdown, no explanations)
9. When using add_row, only specify columns you need in data - other columns will be empty
10. Calculate values in operations first, then reference them in add_row.data using expressions
11. NEVER assign a list of values directly to df[column] or df.loc - always use pd.concat with DataFrame
12. CRITICAL: When removing/replacing special characters (*, ?, +, etc.), ALWAYS use regex=False to avoid regex errors
"""


class ActionPlanBot:
    """Bot for generating data operation action plans"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        """
        Initialize Action Plan Bot
        
        Args:
            api_key: OpenAI API key
            model: Model to use (default: gpt-4o-mini for cost savings)
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OpenAI API key not found")
        
        # Use provided model directly (no env var override) since LLMAgent handles routing
        self.model = model
        self.client = OpenAI(api_key=self.api_key)
        
        # Initialize feedback learner
        try:
            self.feedback_learner = FeedbackLearner()
        except Exception:
            self.feedback_learner = None
        
        # Initialize training data loader
        try:
            self.training_data_loader = TrainingDataLoader()
        except Exception:
            self.training_data_loader = None
    
    def generate_action_plan(
        self,
        user_prompt: str,
        available_columns: List[str],
        sample_data: Optional[List[Dict]] = None,
        sample_explanation: Optional[str] = None
    ) -> Dict:
        """
        Generate action plan with Python code
        
        Args:
            user_prompt: User's request
            available_columns: Available column names
            sample_data: Sample data rows
            sample_explanation: Explanation of sample data
        
        Returns:
            Action plan dict with operations
        """
        try:
            # Build prompt
            prompt = get_prompt_with_context(user_prompt, available_columns, sample_data)
            
            # Get knowledge base summary
            kb_summary = get_knowledge_base_summary()
            
            # Get task suggestions
            task_suggestions = get_task_decision_guide(user_prompt)
            
            # Get similar examples
            similar_examples_text = ""
            all_examples = []
            
            if self.training_data_loader:
                try:
                    training_examples = self.training_data_loader.get_examples_for_prompt(user_prompt, limit=3)
                    all_examples.extend(training_examples)
                except Exception:
                    pass
            
            if self.feedback_learner:
                try:
                    feedback_examples = self.feedback_learner.get_similar_successful_examples(user_prompt, limit=2)
                    for ex in feedback_examples:
                        all_examples.append({
                            "prompt": ex["prompt"],
                            "action_plan": ex["action_plan"]
                        })
                except Exception:
                    pass
            
            if all_examples:
                similar_examples_text = "\n\nFEW-SHOT LEARNING EXAMPLES:\n"
                for i, ex in enumerate(all_examples[:5], 1):
                    similar_examples_text += f"\nExample {i}:\n"
                    similar_examples_text += f"User: {ex['prompt']}\n"
                    similar_examples_text += f"Response: {json.dumps(ex['action_plan'], indent=2)}\n"
            
            sample_explanation_text = ""
            if sample_explanation:
                sample_explanation_text = f"\n\nDATA SAMPLE SUMMARY:\n{sample_explanation}\n"
            
            # Get column mapping info (Excel letters â†’ actual column names)
            column_mapping = get_column_mapping_info(available_columns)
            
            full_prompt = f"""You are a data operations assistant. Return ONLY valid JSON.

CRITICAL: Generate Python code for ALL operations. The backend will execute your code directly.

KNOWLEDGE BASE CONTEXT:
{kb_summary}

TASK DECISION HINT:
Suggested task: {task_suggestions.get('suggested_task', 'auto-detect')}
Reasoning: {', '.join(task_suggestions.get('reasoning', []))}
{column_mapping}
{similar_examples_text}
{sample_explanation_text}

{prompt}

Return your response as a valid JSON object with NO markdown, NO code blocks, NO explanations.
Include "operations" array with "python_code" for each operation.
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": ACTION_PLAN_SYSTEM_PROMPT},
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.1,
                top_p=0.95,
            )
            
            content = response.choices[0].message.content.strip()
            logger.info(f"ðŸ“¥ Raw LLM response (first 500 chars): {content[:500]}")
            
            # Extract JSON
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            # Parse JSON
            try:
                action_plan = json.loads(content)
                logger.info(f"âœ… Successfully parsed action plan JSON")
                logger.info(f"Action plan keys: {list(action_plan.keys())}")
                
                # Log conditional_format if present
                if "conditional_format" in action_plan:
                    logger.info(f"âœ… Conditional format found in action plan!")
                    logger.info(f"Conditional format structure: {json.dumps(action_plan['conditional_format'], indent=2)}")
                else:
                    logger.warning(f"âš ï¸ No 'conditional_format' field in action plan!")
                    logger.info(f"Full action plan structure: {json.dumps({k: type(v).__name__ for k, v in action_plan.items()}, indent=2)}")
            except json.JSONDecodeError:
                import re
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
                if json_match:
                    action_plan = json.loads(json_match.group())
                    logger.info(f"âœ… Successfully parsed action plan JSON from regex extraction")
                    logger.info(f"Action plan keys: {list(action_plan.keys())}")
                    
                    if "conditional_format" in action_plan:
                        logger.info(f"âœ… Conditional format found in action plan!")
                        logger.info(f"Conditional format structure: {json.dumps(action_plan['conditional_format'], indent=2)}")
                    else:
                        logger.warning(f"âš ï¸ No 'conditional_format' field in action plan!")
                else:
                    logger.error(f"âŒ Could not parse JSON from response: {content[:200]}")
                    raise ValueError(f"Could not parse JSON from response: {content[:200]}")
            
            # Normalize action plan
            logger.info(f"ðŸ” Action plan before normalization - operations count: {len(action_plan.get('operations', []))}")
            normalized_plan = self._normalize_action_plan(action_plan)
            logger.info(f"ðŸ” Action plan after normalization - operations count: {len(normalized_plan.get('operations', []))}")
            if normalized_plan.get('operations'):
                logger.info(f"ðŸ” Operations descriptions: {[op.get('description', 'No description') for op in normalized_plan.get('operations', [])]}")
            
            prompt_tokens = getattr(response.usage, "prompt_tokens", 0) or 0
            completion_tokens = getattr(response.usage, "completion_tokens", 0) or 0
            tokens_used = prompt_tokens + completion_tokens
            
            logger.info(f"ActionPlanBot tokens: prompt={prompt_tokens}, completion={completion_tokens}, total={tokens_used}")
            
            return {
                "action_plan": normalized_plan,
                "tokens_used": tokens_used
            }
            
        except Exception as e:
            logger.error(f"ActionPlanBot failed: {str(e)}")
            raise RuntimeError(f"Action plan generation failed: {str(e)}")
    
    def _normalize_action_plan(self, action_plan: Dict) -> Dict:
        """Normalize and validate action plan structure"""
        normalized = {
            "operations": action_plan.get("operations", []),
        }
        
        # Add optional fields - preserve ALL fields from action plan
        if "add_row" in action_plan:
            normalized["add_row"] = action_plan["add_row"]
        
        if "add_column" in action_plan:
            normalized["add_column"] = action_plan["add_column"]
        
        if "delete_column" in action_plan:
            normalized["delete_column"] = action_plan["delete_column"]
        
        if "delete_rows" in action_plan:
            normalized["delete_rows"] = action_plan["delete_rows"]
        
        if "sort" in action_plan:
            normalized["sort"] = action_plan["sort"]
        
        if "conditional_format" in action_plan:
            normalized["conditional_format"] = action_plan["conditional_format"]
        
        if "format" in action_plan:
            normalized["format"] = action_plan["format"]
        
        if "filters" in action_plan:
            normalized["filters"] = action_plan["filters"]
        
        if "task" in action_plan:
            normalized["task"] = action_plan["task"]
        
        # Ensure operations is a list
        if not isinstance(normalized["operations"], list):
            normalized["operations"] = []
        
        # Validate each operation has python_code
        for op in normalized["operations"]:
            if "python_code" not in op:
                logger.warning(f"Operation missing python_code: {op}")
        
        return normalized

